{"cells": [{"cell_type": "code", "execution_count": 1, "id": "582f9005-9ad3-4a59-9e39-abd9fb19994d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/10/28 23:02:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n                                                                                \r"}], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nspark=SparkSession.builder\\\n      .appName(\"hive-practice-396920\")\\\n      .enableHiveSupport()\\\n      .getOrCreate()\n\nhdfs_path1='/tmp/test1/ad_campaigns_data.json'\nhdfs_path2='/tmp/test1/user_profile_data.json'\nhdfs_path3='/tmp/test1/stores_data.json'\nadf=spark.read.format('json').option('multiline','true').load(hdfs_path1)\nudf=spark.read.format('json').option('multiline','true').load(hdfs_path2)\nsdf=spark.read.format('json').option('multiline','true').load(hdfs_path3)"}, {"cell_type": "code", "execution_count": 2, "id": "34d339d1-0e20-40f2-bf23-aebe211e9920", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n|campaign_country|campaign_id|       campaign_name|device_type|          event_time|event_type|os_type| place_id|            user_id|\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n|             USA|    ABCDFAE|Food category tar...|      apple|2018-10-12T13:10:...|impression|    ios|CASSBB-11|1264374214654454321|\n|             USA|    ABCDFAE|Food category tar...|   MOTOROLA|2018-10-12T13:09:...|impression|android|CADGBD-13|1674374214654454321|\n|             USA|    ABCDFAE|Food category tar...|    SAMSUNG|2018-10-12T13:10:...|  video ad|android|BADGBA-12|   5747421465445443|\n|             USA|    ABCDFAE|Food category tar...|    SAMSUNG|2018-10-12T13:10:...|     click|android|CASSBB-11|1864374214654454132|\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 6:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+-------+-------+--------------------+\n|campaign_id|      date|hour|   type|  value|               event|\n+-----------+----------+----+-------+-------+--------------------+\n|    ABCDFAE|2018-10-12|  13|os_type|android|{click -> 1, impr...|\n|    ABCDFAE|2018-10-12|  13|os_type|    ios|   {impression -> 1}|\n+-----------+----------+----+-------+-------+--------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "adf.show()\n\nad_n=adf.groupBy(\"campaign_id\",\n                        substring(col(\"event_time\"), 0, 10).alias(\"date\"),\n                        substring(col(\"event_time\"),12, 2).alias(\"hour\"),\n                        col(\"os_type\"),\n                        col(\"event_type\")\n                       ).agg(count(\"event_type\").alias(\"events\"))\\\n                        .selectExpr(\n                          \"campaign_id\",\n                          \"date\",\n                          \"hour\",\n                          \"'os_type' as type\",\n                          \"os_type as value\",\n                          \"struct(event_type, events) as event\"\n                          ) \\\n                          .groupBy(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\") \\\n                          .agg(collect_list(\"event\").alias(\"events\")) \\\n                          .selectExpr(\n                              \"campaign_id\",\n                              \"date\",\n                              \"hour\",\n                              \"type\",\n                              \"value\",\n                              \"map_from_entries(events) as event\"\n                          )\n\nad_n.show()"}, {"cell_type": "code", "execution_count": 3, "id": "5512d070-320d-4a24-a3f9-d7c7fbdb6378", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+----------+-------------+--------------------+\n|campaign_id|      date|hour|      type|        value|               event|\n+-----------+----------+----+----------+-------------+--------------------+\n|    ABCDFAE|2018-10-12|  13|store name|     McDonald|{click -> 1, impr...|\n|    ABCDFAE|2018-10-12|  13|store name|   BurgerKing|{impression -> 1,...|\n|    ABCDFAE|2018-10-12|  13|store name|shoppers stop|     {video ad -> 1}|\n+-----------+----------+----+----------+-------------+--------------------+\n\n"}], "source": "asjoin=adf.join(sdf,array_contains(sdf.place_ids,adf.place_id),\"left\")\\\n          .groupBy('campaign_id',\n                   substring('event_time',0,10).alias('date'),\n                   substring('event_time',12,2).alias('hour'),\n                   'store_name',\n                   'event_type'\n                  ).agg(count('event_type').alias('events'))\\\n          .selectExpr('campaign_id',\n                     'date',\n                     'hour',\n                     '\"store name\" as type',\n                     'store_name as value',\n                     'struct(event_type,events) as event_dict')\\\n          .groupBy('campaign_id',\n                   'date',\n                   'hour',\n                   'type',\n                   'value'\n                   ).agg(collect_list('event_dict').alias('event'))\\\n          .select('campaign_id',\n                      'date',\n                      'hour',\n                      'type',\n                      'value',\n                      map_from_entries('event').alias('event'))\nasjoin.show()"}, {"cell_type": "code", "execution_count": 4, "id": "d602c60a-cbac-4900-8896-2666c5666a88", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+------+------+--------------------+\n|campaign_id|      date|hour|  type| value|               event|\n+-----------+----------+----+------+------+--------------------+\n|    ABCDFAE|2018-10-12|  13|gender|  male|{impression -> 1,...|\n|    ABCDFAE|2018-10-12|  13|gender|female|   {impression -> 1}|\n+-----------+----------+----+------+------+--------------------+\n\n"}], "source": "aujoin=adf.join(udf, adf.user_id == udf.user_id, \"left\")\\\n                            .select(\"campaign_id\",\n                                    substring(\"event_time\", 0, 10).alias(\"date\"),\n                                    substring(\"event_time\", 12, 2).alias(\"hour\"),\n                                    lit('gender').alias(\"type\"),\n                                    col(\"gender\").alias(\"value\"),\n                                    \"event_type\")\\\n                            .groupBy(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\", \"event_type\")\\\n                            .agg(count(\"event_type\").alias(\"event_count\"))\\\n                            .select(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\", struct(\"event_type\", \"event_count\").alias(\"events_map\"))\\\n                            .groupBy(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\")\\\n                            .agg(collect_list(\"events_map\").alias(\"map_list\"))\\\n                            .select(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\", map_from_entries(\"map_list\").alias(\"event\"))\naujoin.show()"}, {"cell_type": "code", "execution_count": 6, "id": "be4b4a24-c2c7-4a07-b386-b362485da4ff", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/10/28 21:41:57 WARN SetCommand: 'SET hive.exec.dynamic.partition.mode=nonstrict' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition.mode) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.\n23/10/28 21:41:57 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n23/10/28 21:41:57 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n                                                                                \r"}], "source": "spark.sql(\"\"\"set hive.exec.dynamic.partition.mode=nonstrict\"\"\")\nspark.sql(\"\"\"USE a1\"\"\")\nspark.sql(\"\"\"\n             CREATE TABLE IF NOT EXISTS ad2_n(\n             campaign_id STRING,\n             hour STRING,\n             type STRING,\n             value STRING,\n             event map<string,bigint>\n             )PARTITIONED BY (date STRING)\n\"\"\")\nad_n.select('campaign_id','hour','type','value','event','date').write.mode('append').insertInto('ad1_n')"}, {"cell_type": "code", "execution_count": null, "id": "179ea7ab-8323-4e55-8594-4f03b068ae39", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}